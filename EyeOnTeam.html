<!DOCTYPE html>
<html>
<head>
    <title>Tactical X-ray Vision</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<div class="mainPanel">

    <div class='pageTitle'>Project - Tactical X-ray Vision</div>

    <div id='navBar' class='navBar'>
        <button class='navButton' id='navHome'>Home</button>
        <button class='navButton' id='navProjects'>Projects</button>
        <button class='navButton' id='navLiterature'>Literature</button>
        <button class='navButton' id='navResume'>Resume</button>
    </div>

    <div>
        <video controls="controls" src="videos/EOT_demo_house_2.mp4" type="video/mp4"></video>
    </div>

    <div class="lightPanel">

        <div class="sectionTitleLight">"Eye On Team" - X-ray vision for indoor teams</div>

        <iframe width=50% height="300px" src="https://www.youtube.com/embed/bUXYAX7k_V0">
        </iframe>

        <p>In August 2018 I received $50k in funding for a proposal to develop a system that would allow tactical
            team members to maintain virtual line of sight with one another in indoor environments using augmented
            reality. We used the Unity Game Engine to build an application for Microsoft's HoloLens that would
            display 3D representations of teammate locations indoors. We developed peripheral hardware that performed
            indoor node localization with RF as well as collected data about individual motion (dead reckoning)
            to allow a fusion of location information to improve traking accuracy indoors.</p>
        <p>
            Results from this work were presented in January 2021 at the APL XR Symposium. This video shows talks
            from day 1 of the symposium. My talk is first and describes the project in greater detail.
        </p>

    </div>

</div>

<script src="procedurals.js"></script>
</body>
</html>